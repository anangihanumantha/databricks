{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b02166ae-2551-4de7-8e67-d2a7ba953be7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession\n",
    "from pyspark.sql.types import *\n",
    "from datetime import date\n",
    "\n",
    "spark = DatabricksSession.builder.getOrCreate()\n",
    "\n",
    "# Create a Spark DataFrame consisting of high and low temperatures\n",
    "# by airport code and date.\n",
    "schema = StructType([\n",
    "  StructField('AirportCode', StringType(), False),\n",
    "  StructField('Date', DateType(), False),\n",
    "  StructField('TempHighF', IntegerType(), False),\n",
    "  StructField('TempLowF', IntegerType(), False)\n",
    "])\n",
    "\n",
    "data = [\n",
    "  [ 'BLI', date(2021, 4, 3), 52, 43],\n",
    "  [ 'BLI', date(2021, 4, 2), 50, 38],\n",
    "  [ 'BLI', date(2021, 4, 1), 52, 41],\n",
    "  [ 'PDX', date(2021, 4, 3), 64, 45],\n",
    "  [ 'PDX', date(2021, 4, 2), 61, 41],\n",
    "  [ 'PDX', date(2021, 4, 1), 66, 39],\n",
    "  [ 'SEA', date(2021, 4, 3), 57, 43],\n",
    "  [ 'SEA', date(2021, 4, 2), 54, 39],\n",
    "  [ 'SEA', date(2021, 4, 1), 56, 41]\n",
    "]\n",
    "\n",
    "temps = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Create a table on the Databricks cluster and then fill\n",
    "# the table with the DataFrame's contents.\n",
    "# If the table already exists from a previous run,\n",
    "# delete it first.\n",
    "spark.sql('USE default')\n",
    "spark.sql('DROP TABLE IF EXISTS zzz_demo_temps_table')\n",
    "temps.write.saveAsTable('zzz_demo_temps_table')\n",
    "\n",
    "# Query the table on the Databricks cluster, returning rows\n",
    "# where the airport code is not BLI and the date is later\n",
    "# than 2021-04-01. Group the results and order by high\n",
    "# temperature in descending order.\n",
    "df_temps = spark.sql(\"SELECT * FROM zzz_demo_temps_table \" \\\n",
    "  \"WHERE AirportCode != 'BLI' AND Date > '2021-04-01' \" \\\n",
    "  \"GROUP BY AirportCode, Date, TempHighF, TempLowF \" \\\n",
    "  \"ORDER BY TempHighF DESC\")\n",
    "df_temps.show()\n",
    "\n",
    "# Results:\n",
    "#\n",
    "# +-----------+----------+---------+--------+\n",
    "# |AirportCode|      Date|TempHighF|TempLowF|\n",
    "# +-----------+----------+---------+--------+\n",
    "# |        PDX|2021-04-03|       64|      45|\n",
    "# |        PDX|2021-04-02|       61|      41|\n",
    "# |        SEA|2021-04-03|       57|      43|\n",
    "# |        SEA|2021-04-02|       54|      39|\n",
    "# +-----------+----------+---------+--------+\n",
    "\n",
    "# Clean up by deleting the table from the Databricks cluster.\n",
    "spark.sql('DROP TABLE zzz_demo_temps_table')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
